name: Profanity Check

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

on: [push, pull_request]

jobs:
  check-profanity:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install better-profanity

      - name: Run profanity check (parallel)
        id: profanity
        run: |
          python - <<'EOF'
          import os
          import sys
          from multiprocessing import Pool, cpu_count
          from better_profanity import profanity

          profanity.load_censor_words()

          extensions = ['.md', '.qmd']

          # Gather all files to check
          files_to_check = []
          for root, dirs, files in os.walk('.'):
              for file in files:
                  if any(file.endswith(ext) for ext in extensions):
                      files_to_check.append(os.path.join(root, file))

          def check_file(path):
              try:
                  with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                      content = f.read()
                      words_found = [w for w in content.split() if profanity.contains_profanity(w)]
                      if words_found:
                          return path, words_found
              except Exception as e:
                  print(f"⚠️ Could not read {path}: {e}")
              return None, []

          # Parallel scan
          with Pool(cpu_count()) as pool:
              results = pool.map(check_file, files_to_check)

          # Filter profane files
          profane_files = [(f, words) for f, words in results if words]
          total_files = len(files_to_check)
          profane_count = len(profane_files)

          # Write artifact report
          report_file = 'profanity_report.txt'
          with open(report_file, 'w', encoding='utf-8') as f:
              if profane_files:
                  f.write("Profanity detected in the following files:\n")
                  for file_path, words in profane_files:
                      f.write(f"{file_path}: {', '.join(words)}\n")
              else:
                  f.write("No profanity detected.\n")

          # Export report file for next step
          with open(os.environ['GITHUB_OUTPUT'], 'a') as gh_out:
              gh_out.write(f"report_file={report_file}\n")

          # Write GitHub Actions job summary with red highlight for failure
          summary_path = os.environ['GITHUB_STEP_SUMMARY']
          with open(summary_path, 'a') as summary:
              summary.write(f"## Profanity Check Summary\n")
              summary.write(f"**Total files scanned:** {total_files}\n\n")
              if profane_files:
                  summary.write(f"**Files with profanity:** <span style='color:red'>{profane_count}</span>\n\n")
                  summary.write("### Offending files and words\n")
                  for file_path, words in profane_files:
                      summary.write(f"- {file_path}: {', '.join(words)}\n")
              else:
                  summary.write("**Files with profanity:** 0 ✅\n")

          # Add annotations for each profane file
          for file_path, words in profane_files:
              print(f"::error file={file_path}::Profanity detected: {', '.join(words)}")

          # Fail workflow if any profanity
          if profane_files:
              sys.exit("❌ Profanity detected. Failing workflow.")
          else:
              print("✅ No profanity detected.")
          EOF

      - name: Upload profanity report
        uses: actions/upload-artifact@v4
        with:
          name: profanity-report
          path: ${{ steps.profanity.outputs.report_file }}
